{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "# from google.colab import drive\n",
    "import os\n",
    "import gc\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "# def mount():\n",
    "#   drive.mount('/content/drive')\n",
    "#   os.chdir(\"/content/drive/My Drive/SLAss2\")\n",
    "# mount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-ad997d494748>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test = pd.read_csv(\"dtest123.dat\", delimiter = \"  \", header = None)\n",
      "<ipython-input-2-ad997d494748>:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  minitrain = pd.read_csv(\"dtrain123.dat\", delimiter = \"  \", header = None)\n"
     ]
    }
   ],
   "source": [
    "# train = pd.read_csv(\"dtrain123.dat\", delimiter = \"  \", header = None)\n",
    "test = pd.read_csv(\"data/dtest123.dat\", delimiter = \"  \", header = None)\n",
    "train = pd.read_csv(\"data/zipcombo.dat\", delimiter = \" \", header = None)\n",
    "train.shape\n",
    "minitrain = pd.read_csv(\"data/dtrain123.dat\", delimiter = \"  \", header = None)\n",
    "train = np.array(train)\n",
    "xtrain = train[:,1:257]\n",
    "ytrain = train[:,0]\n",
    "one = np.array(minitrain)\n",
    "xone = one[:, 1:257]\n",
    "yone = one[:,0]\n",
    "test = np.array(test)\n",
    "xtest = test[:, 1:]\n",
    "ytest = test[:,0]\n",
    "def split_data(fullK, jtrain, jtest, y):\n",
    "    Ktrain = fullK[jtrain][:,jtrain].copy()\n",
    "    Ktest =  fullK[jtrain][:,jtest].copy()\n",
    "    ytrain = y[jtrain]\n",
    "    ytest = y[jtest]\n",
    "    return Ktrain, ytrain, Ktest, ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kernel_perceptron:\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        self.alpha = np.zeros((self.N, 1))\n",
    "        self.accs = []\n",
    "        self.w = np.zeros((N, 1))\n",
    "    def train(self, K, y, d = 2, epochs = 1, alt = True):\n",
    "        if alt == False:\n",
    "            if len(self.alpha) != len(K):\n",
    "                self.N = len(K)\n",
    "                self.alpha = np.zeros((len(K), 1))\n",
    "            for epoch in range(epochs):\n",
    "                mistakes = 0\n",
    "                yhats = np.zeros(self.N)\n",
    "                js = np.arange(self.N)\n",
    "                np.random.shuffle(js)\n",
    "                for i in js:\n",
    "                    yhat = np.sign(np.sign((K[:,i].dot(self.alpha))))\n",
    "                    if yhat != y[i]:\n",
    "                        self.alpha[i] += y[i]\n",
    "                        mistakes += 1\n",
    "                    # else:\n",
    "                    #     self.alpha[js[i]] = 0\n",
    "                    yhats[i] = yhat\n",
    "                self.accs.append(1 - mistakes/self.N)\n",
    "            return yhats\n",
    "        else:\n",
    "            js = np.arange(self.N)\n",
    "            np.random.shuffle(js)\n",
    "            yhat = np.sign(K.dot(self.alpha)).flatten()\n",
    "            for i in range(self.N):\n",
    "                if yhat[js[i]] != y[js[i]]:\n",
    "                    self.alpha[js[i]] += y[js[i]]\n",
    "                    yhat[js[i:]] = np.sign(K[js[i:], :].dot(self.alpha)).flatten()\n",
    "\n",
    "    \n",
    "    def predict(self, Ktest, ytest):\n",
    "        return Ktest.T.dot(self.alpha).flatten()\n",
    "                \n",
    "def K(p, q, d = 2):\n",
    "    return (p.T.dot(q))**d\n",
    "\n",
    "# def GaussK(p, q, c):\n",
    "#     print(np.sum((p-q)**2))\n",
    "#     return np.exp(-c * np.sum((p-q)**2))\n",
    "\n",
    "class onevsall:\n",
    "    def __init__(self, xtrain, ytrain, xtest = None, ytest = None, kernel = K, d = 2, ks = None):\n",
    "        self.N = len(xtrain)\n",
    "\n",
    "        self.models = []\n",
    "        self.accs = []\n",
    "        self.testaccs = []\n",
    "        self.d = d\n",
    "        self.x, self.xtest = xtrain, xtest\n",
    "        self.y, self.ytest = ytrain, ytest\n",
    "        if ks == None:\n",
    "            self.K = np.zeros((self.N, self.N))\n",
    "            for i in range(self.N):\n",
    "                for j in range(i, self.N):\n",
    "                    # print(self.x[i], self.x[j], d)\n",
    "                    self.K[i,j] = K(self.x[i], self.x[j], d)\n",
    "            self.K = self.K + self.K.T - np.diag(self.K.diagonal())\n",
    "            self.Ktest = np.zeros((self.N, len(self.xtest)))\n",
    "            for i in range(self.N):\n",
    "                for j in range(len(self.xtest)):\n",
    "                    self.Ktest[i,j] = K(self.x[i], self.xtest[j], d)\n",
    "        else:\n",
    "            self.N = len(ks[0])\n",
    "            self.K, self.Ktest = ks\n",
    "    \n",
    "    def train(self, print_accs = True, alt = False):\n",
    "        self.vals = range(int(max(self.y)+1)) # final yval doesn't need model\n",
    "        if len(self.models) == 0:\n",
    "            self.ytemps = []\n",
    "            for val in self.vals:\n",
    "                ytemp = self.y.copy()\n",
    "                ytemp[ytemp != val] = -1\n",
    "                ytemp[ytemp == val] = 1\n",
    "                self.add_model(ytemp)\n",
    "                self.ytemps.append(ytemp.copy())\n",
    "        for val in self.vals:\n",
    "            self.models[val].train(self.K, self.ytemps[val], epochs = 1, alt = alt)\n",
    "\n",
    "        if print_accs:\n",
    "            yhat = self.predict(self.K, self.y)\n",
    "            acc = np.mean(yhat.reshape(len(yhat), 1) == self.y.reshape(len(yhat), 1))\n",
    "            self.accs.append(acc)            \n",
    "            yhattest = self.predict(self.Ktest, self.ytest)\n",
    "            testacc = np.mean(yhattest.reshape(len(yhattest), 1) == self.ytest.reshape(len(yhattest), 1))\n",
    "            self.testaccs.append(testacc)\n",
    "            print(f\"Training Accuracy: {acc}. Testing Accuracy: {testacc}\")\n",
    "            return acc, testacc\n",
    "\n",
    "    def add_model(self, ytrain):\n",
    "        model = kernel_perceptron(self.N)\n",
    "        # model.train(self.K, ytrain, epochs = epochs, d = self.d)\n",
    "        self.models.append(model)\n",
    "    \n",
    "    def predict(self, k, ytest, full = False):\n",
    "        preds = np.zeros((k.shape[1], len(self.models)))\n",
    "        yhat = np.zeros(k.shape[1])\n",
    "        for i, model in enumerate(self.models):\n",
    "            preds[:,i] = model.predict(k, ytest)\n",
    "        if full == True:\n",
    "            return preds\n",
    "        return preds.argmax(axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RBF(x, c):\n",
    "    edist = squareform(pdist(x, metric = \"euclidean\"))**2\n",
    "    edist /= edist.max()\n",
    "    return np.exp(-c * edist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9995966657703684. Testing Accuracy: 0.9736559139784946\n",
      "3 0 [0. 0.]\n",
      "Training Accuracy: 0.9998655552567894. Testing Accuracy: 0.978494623655914\n",
      "3 0 [0. 0.]\n",
      "Training Accuracy: 0.9997311105135789. Testing Accuracy: 0.9682795698924731\n",
      "3 0 [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "cs = [3, 5, 6, 6.5, 7, 7.5, 8, 9]\n",
    "metrics = np.zeros((20, len(cs), 2))\n",
    "ntrain = int(0.8*len(xtrain))\n",
    "\n",
    "for ic, c in enumerate(cs):\n",
    "    Kfull = RBF(xtrain, c)\n",
    "    js = np.arange(len(xtrain))\n",
    "    for i in range(20):\n",
    "        np.random.seed(i)\n",
    "        np.random.shuffle(js)\n",
    "        jtrain = js[:ntrain]\n",
    "        jtest = js[ntrain:]\n",
    "        ktrain = Kfull[jtrain][:,jtrain]\n",
    "        ktest = Kfull[jtrain][:,jtest]\n",
    "        xt =  xtrain[jtrain]\n",
    "        yt = ytrain[jtrain]\n",
    "        ytest = ytrain[jtest]\n",
    "        model = onevsall(xt, yt, None, ytest, ks = (ktrain, ktest))\n",
    "        for epoch in range(10):\n",
    "            model.train(False, False)\n",
    "        metrics[i, ic] = model.train(True, False)\n",
    "        print(c, ic, metrics[i, c])\n",
    "    np.save(\"GaussNew1.1\", metrics)\n",
    "    ic += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start\n",
      "0 run : 6.5: 0.966621803499327, 0, None\n",
      "0 run : 7: 0.967563930013459, 0.966621803499327, 6.5\n",
      "0 run : 7.5: 0.9681022880215343, 0.967563930013459, 7\n",
      "0 run : 8: 0.9687752355316286, 0.9681022880215343, 7.5\n",
      "0 run : 9: 0.9694481830417228, 0.9687752355316286, 8\n",
      "0 run : 10: 0.9695827725437417, 0.9694481830417228, 9\n",
      "0 run : 11: 0.9679676985195156, 0.9695827725437417, 10\n",
      "0 run : 12: 0.9644683714670256, 0.9695827725437417, 10\n",
      "0 runs finished. Dstar: 10, Testerr: 0.02580645161290318, Time: 474.79002141952515\n",
      "1 run : 6.5: 0.9652759084791386, 0, None\n",
      "1 run : 7: 0.9667563930013459, 0.9652759084791386, 6.5\n",
      "1 run : 7.5: 0.9664872139973082, 0.9667563930013459, 7\n",
      "1 run : 8: 0.9655450874831762, 0.9667563930013459, 7\n",
      "1 run : 9: 0.9672947510094213, 0.9667563930013459, 7\n",
      "1 run : 10: 0.966756393001346, 0.9672947510094213, 9\n",
      "1 run : 11: 0.9683714670255721, 0.9672947510094213, 9\n",
      "1 run : 12: 0.9631224764468371, 0.9683714670255721, 11\n",
      "1 runs finished. Dstar: 11, Testerr: 0.02311827956989243, Time: 944.1060571670532\n",
      "2 run : 6.5: 0.966756393001346, 0, None\n",
      "2 run : 7: 0.9643337819650069, 0.966756393001346, 6.5\n",
      "2 run : 7.5: 0.9658142664872141, 0.966756393001346, 6.5\n",
      "2 run : 8: 0.9668909825033647, 0.966756393001346, 6.5\n",
      "2 run : 9: 0.968371467025572, 0.9668909825033647, 8\n",
      "2 run : 10: 0.9705248990578735, 0.968371467025572, 9\n",
      "2 run : 11: 0.9663526244952894, 0.9705248990578735, 10\n",
      "2 run : 12: 0.9647375504710634, 0.9705248990578735, 10\n",
      "2 runs finished. Dstar: 10, Testerr: 0.01505376344086018, Time: 1413.5742981433868\n",
      "3 run : 6.5: 0.9654104979811575, 0, None\n",
      "3 run : 7: 0.9664872139973083, 0.9654104979811575, 6.5\n",
      "3 run : 7.5: 0.9668909825033648, 0.9664872139973083, 7\n",
      "3 run : 8: 0.9685060565275909, 0.9668909825033648, 7.5\n",
      "3 run : 9: 0.9687752355316286, 0.9685060565275909, 8\n",
      "3 run : 10: 0.9685060565275909, 0.9687752355316286, 9\n",
      "3 run : 11: 0.9683714670255721, 0.9687752355316286, 9\n",
      "3 run : 12: 0.9674293405114402, 0.9687752355316286, 9\n",
      "3 runs finished. Dstar: 9, Testerr: 0.030645161290322576, Time: 1882.8754148483276\n",
      "4 run : 6.5: 0.9682368775235533, 0, None\n",
      "4 run : 7: 0.9678331090174966, 0.9682368775235533, 6.5\n",
      "4 run : 7.5: 0.9681022880215343, 0.9682368775235533, 6.5\n",
      "4 run : 8: 0.966756393001346, 0.9682368775235533, 6.5\n",
      "4 run : 9: 0.9678331090174965, 0.9682368775235533, 6.5\n",
      "4 run : 10: 0.9671601615074025, 0.9682368775235533, 6.5\n",
      "4 run : 11: 0.9682368775235533, 0.9682368775235533, 6.5\n",
      "4 run : 12: 0.9685060565275909, 0.9682368775235533, 6.5\n",
      "4 runs finished. Dstar: 12, Testerr: 0.025268817204301075, Time: 2341.293913125992\n",
      "5 run : 6.5: 0.9640646029609691, 0, None\n",
      "5 run : 7: 0.9647375504710634, 0.9640646029609691, 6.5\n",
      "5 run : 7.5: 0.9683714670255721, 0.9647375504710634, 7\n",
      "5 run : 8: 0.9671601615074025, 0.9683714670255721, 7.5\n",
      "5 run : 9: 0.9668909825033648, 0.9683714670255721, 7.5\n",
      "5 run : 10: 0.9686406460296098, 0.9683714670255721, 7.5\n",
      "5 run : 11: 0.9670255720053836, 0.9686406460296098, 10\n",
      "5 run : 12: 0.9689098250336475, 0.9686406460296098, 10\n",
      "5 runs finished. Dstar: 12, Testerr: 0.023655913978494647, Time: 2815.7225580215454\n",
      "6 run : 6.5: 0.9664872139973083, 0, None\n",
      "6 run : 7: 0.9671601615074025, 0.9664872139973083, 6.5\n",
      "6 run : 7.5: 0.9664872139973082, 0.9671601615074025, 7\n",
      "6 run : 8: 0.967563930013459, 0.9671601615074025, 7\n",
      "6 run : 9: 0.9667563930013459, 0.967563930013459, 8\n",
      "6 run : 10: 0.966756393001346, 0.967563930013459, 8\n",
      "6 run : 11: 0.9667563930013459, 0.967563930013459, 8\n",
      "6 run : 12: 0.966621803499327, 0.967563930013459, 8\n",
      "6 runs finished. Dstar: 8, Testerr: 0.029569892473118253, Time: 3355.3583087921143\n",
      "7 run : 6.5: 0.9682368775235531, 0, None\n",
      "7 run : 7: 0.9681022880215343, 0.9682368775235531, 6.5\n",
      "7 run : 7.5: 0.9656796769851953, 0.9682368775235531, 6.5\n",
      "7 run : 8: 0.9678331090174966, 0.9682368775235531, 6.5\n",
      "7 run : 9: 0.9671601615074025, 0.9682368775235531, 6.5\n",
      "7 run : 10: 0.9689098250336474, 0.9682368775235531, 6.5\n",
      "7 run : 11: 0.9670255720053836, 0.9689098250336474, 10\n",
      "7 run : 12: 0.9670255720053836, 0.9689098250336474, 10\n",
      "7 runs finished. Dstar: 10, Testerr: 0.01935483870967747, Time: 3860.6238338947296\n",
      "8 run : 6.5: 0.9659488559892329, 0, None\n",
      "8 run : 7: 0.9660834454912517, 0.9659488559892329, 6.5\n",
      "8 run : 7.5: 0.9655450874831764, 0.9660834454912517, 7\n",
      "8 run : 8: 0.9660834454912518, 0.9660834454912517, 7\n",
      "8 run : 9: 0.9678331090174968, 0.9660834454912518, 8\n",
      "8 run : 10: 0.965814266487214, 0.9678331090174968, 9\n",
      "8 run : 11: 0.9690444145356663, 0.9678331090174968, 9\n",
      "8 run : 12: 0.9670255720053836, 0.9690444145356663, 11\n",
      "8 runs finished. Dstar: 11, Testerr: 0.02741935483870972, Time: 4473.8026559352875\n",
      "9 run : 6.5: 0.9663526244952895, 0, None\n",
      "9 run : 7: 0.965814266487214, 0.9663526244952895, 6.5\n",
      "9 run : 7.5: 0.9655450874831765, 0.9663526244952895, 6.5\n",
      "9 run : 8: 0.966621803499327, 0.9663526244952895, 6.5\n",
      "9 run : 9: 0.9672947510094213, 0.966621803499327, 8\n",
      "9 run : 10: 0.9668909825033648, 0.9672947510094213, 9\n",
      "9 run : 11: 0.9655450874831765, 0.9672947510094213, 9\n",
      "9 run : 12: 0.9650067294751011, 0.9672947510094213, 9\n",
      "9 runs finished. Dstar: 9, Testerr: 0.019892473118279574, Time: 5093.857113838196\n",
      "10 run : 6.5: 0.9644683714670257, 0, None\n",
      "10 run : 7: 0.9667563930013459, 0.9644683714670257, 6.5\n",
      "10 run : 7.5: 0.9695827725437417, 0.9667563930013459, 7\n",
      "10 run : 8: 0.9687752355316286, 0.9695827725437417, 7.5\n",
      "10 run : 9: 0.968371467025572, 0.9695827725437417, 7.5\n",
      "10 run : 10: 0.96742934051144, 0.9695827725437417, 7.5\n",
      "10 run : 11: 0.9663526244952895, 0.9695827725437417, 7.5\n",
      "10 run : 12: 0.9667563930013459, 0.9695827725437417, 7.5\n",
      "10 runs finished. Dstar: 7.5, Testerr: 0.02204301075268822, Time: 5719.647377729416\n",
      "11 run : 6.5: 0.9646029609690445, 0, None\n",
      "11 run : 7: 0.9629878869448184, 0.9646029609690445, 6.5\n",
      "11 run : 7.5: 0.9635262449528936, 0.9646029609690445, 6.5\n",
      "11 run : 8: 0.9666218034993271, 0.9646029609690445, 6.5\n",
      "11 run : 9: 0.9668909825033648, 0.9666218034993271, 8\n",
      "11 run : 10: 0.967563930013459, 0.9668909825033648, 9\n",
      "11 run : 11: 0.9648721399730821, 0.967563930013459, 10\n",
      "11 run : 12: 0.9655450874831764, 0.967563930013459, 10\n",
      "11 runs finished. Dstar: 10, Testerr: 0.03010752688172047, Time: 6301.652349948883\n",
      "12 run : 6.5: 0.9668909825033648, 0, None\n",
      "12 run : 7: 0.965006729475101, 0.9668909825033648, 6.5\n",
      "12 run : 7.5: 0.967563930013459, 0.9668909825033648, 6.5\n",
      "12 run : 8: 0.9648721399730822, 0.967563930013459, 7.5\n",
      "12 run : 9: 0.9647375504710632, 0.967563930013459, 7.5\n",
      "12 run : 10: 0.9668909825033648, 0.967563930013459, 7.5\n",
      "12 run : 11: 0.9670255720053836, 0.967563930013459, 7.5\n",
      "12 run : 12: 0.9682368775235533, 0.967563930013459, 7.5\n",
      "12 runs finished. Dstar: 12, Testerr: 0.02741935483870972, Time: 6928.607055902481\n",
      "13 run : 6.5: 0.9656796769851953, 0, None\n",
      "13 run : 7: 0.9697173620457605, 0.9656796769851953, 6.5\n",
      "13 run : 7.5: 0.9674293405114401, 0.9697173620457605, 7\n",
      "13 run : 8: 0.9685060565275909, 0.9697173620457605, 7\n",
      "13 run : 9: 0.9648721399730821, 0.9697173620457605, 7\n",
      "13 run : 10: 0.9671601615074024, 0.9697173620457605, 7\n",
      "13 run : 11: 0.9691790040376852, 0.9697173620457605, 7\n",
      "13 run : 12: 0.9686406460296098, 0.9697173620457605, 7\n",
      "13 runs finished. Dstar: 7, Testerr: 0.03279569892473122, Time: 7586.288089752197\n",
      "14 run : 6.5: 0.9699865410497981, 0, None\n",
      "14 run : 7: 0.9690444145356663, 0.9699865410497981, 6.5\n",
      "14 run : 7.5: 0.9676985195154778, 0.9699865410497981, 6.5\n",
      "14 run : 8: 0.9687752355316286, 0.9699865410497981, 6.5\n",
      "14 run : 9: 0.9701211305518171, 0.9699865410497981, 6.5\n",
      "14 run : 10: 0.9689098250336474, 0.9701211305518171, 9\n",
      "14 run : 11: 0.9722745625841185, 0.9701211305518171, 9\n",
      "14 run : 12: 0.9698519515477794, 0.9722745625841185, 11\n",
      "14 runs finished. Dstar: 11, Testerr: 0.025268817204301075, Time: 8278.689710140228\n",
      "15 run : 6.5: 0.9676985195154779, 0, None\n",
      "15 run : 7: 0.966621803499327, 0.9676985195154779, 6.5\n",
      "15 run : 7.5: 0.9670255720053836, 0.9676985195154779, 6.5\n",
      "15 run : 8: 0.966756393001346, 0.9676985195154779, 6.5\n",
      "15 run : 9: 0.9691790040376851, 0.9676985195154779, 6.5\n",
      "15 run : 10: 0.9663526244952894, 0.9691790040376851, 9\n",
      "15 run : 11: 0.9675639300134591, 0.9691790040376851, 9\n",
      "15 run : 12: 0.9691790040376851, 0.9691790040376851, 9\n",
      "15 runs finished. Dstar: 9, Testerr: 0.022580645161290325, Time: 9356.501225233078\n",
      "16 run : 6.5: 0.9639300134589504, 0, None\n",
      "16 run : 7: 0.9620457604306865, 0.9639300134589504, 6.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 run : 7.5: 0.966621803499327, 0.9639300134589504, 6.5\n",
      "16 run : 8: 0.9668909825033647, 0.966621803499327, 7.5\n",
      "16 run : 9: 0.9675639300134591, 0.9668909825033647, 8\n",
      "16 run : 10: 0.9640646029609691, 0.9675639300134591, 9\n",
      "16 run : 11: 0.9631224764468371, 0.9675639300134591, 9\n",
      "16 run : 12: 0.9656796769851951, 0.9675639300134591, 9\n",
      "16 runs finished. Dstar: 9, Testerr: 0.02580645161290318, Time: 10201.839571237564\n",
      "17 run : 6.5: 0.9664872139973083, 0, None\n",
      "17 run : 7: 0.9658142664872142, 0.9664872139973083, 6.5\n",
      "17 run : 7.5: 0.9648721399730821, 0.9664872139973083, 6.5\n",
      "17 run : 8: 0.9668909825033648, 0.9664872139973083, 6.5\n",
      "17 run : 9: 0.97092866756393, 0.9668909825033648, 8\n",
      "17 run : 10: 0.9683714670255721, 0.97092866756393, 9\n",
      "17 run : 11: 0.9662180349932706, 0.97092866756393, 9\n",
      "17 run : 12: 0.968371467025572, 0.97092866756393, 9\n",
      "17 runs finished. Dstar: 9, Testerr: 0.02741935483870972, Time: 10659.737754106522\n",
      "18 run : 6.5: 0.9635262449528936, 0, None\n",
      "18 run : 7: 0.9621803499327053, 0.9635262449528936, 6.5\n",
      "18 run : 7.5: 0.9659488559892329, 0.9635262449528936, 6.5\n",
      "18 run : 8: 0.9639300134589504, 0.9659488559892329, 7.5\n",
      "18 run : 9: 0.9629878869448183, 0.9659488559892329, 7.5\n",
      "18 run : 10: 0.9654104979811574, 0.9659488559892329, 7.5\n",
      "18 run : 11: 0.965006729475101, 0.9659488559892329, 7.5\n",
      "18 run : 12: 0.9646029609690444, 0.9659488559892329, 7.5\n",
      "18 runs finished. Dstar: 7.5, Testerr: 0.02204301075268822, Time: 11114.437234163284\n",
      "19 run : 6.5: 0.9633916554508749, 0, None\n",
      "19 run : 7: 0.9670255720053836, 0.9633916554508749, 6.5\n",
      "19 run : 7.5: 0.9647375504710634, 0.9670255720053836, 7\n",
      "19 run : 8: 0.9682368775235531, 0.9670255720053836, 7\n",
      "19 run : 9: 0.967563930013459, 0.9682368775235531, 8\n",
      "19 run : 10: 0.9668909825033649, 0.9682368775235531, 8\n",
      "19 run : 11: 0.9656796769851952, 0.9682368775235531, 8\n",
      "19 run : 12: 0.9663526244952894, 0.9682368775235531, 8\n",
      "19 runs finished. Dstar: 8, Testerr: 0.029569892473118253, Time: 11567.414289951324\n"
     ]
    }
   ],
   "source": [
    "cs = [1, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n",
    "ntrain = int(0.8*len(xtrain))\n",
    "metrics = np.zeros((len(cs), 20, 2))\n",
    "nfold = int(0.8 * ntrain)\n",
    "nfoldtest = int(ntrain - nfold)\n",
    "cstars = np.zeros(20)\n",
    "testerr = np.zeros(20)\n",
    "confusion_matrix = np.zeros((10, 10))\n",
    "cvfullnew = np.zeros((len(cs), 20, 5, 2))\n",
    "print(\"Start\")\n",
    "start = time.time()\n",
    "for i in range(20):\n",
    "    np.random.seed(i)\n",
    "    js = np.arange(len(xtrain))\n",
    "    np.random.shuffle(js)\n",
    "    jtrain = js[:ntrain]\n",
    "    jtest = js[ntrain:]\n",
    "    # jtrain = np.arange(0, 5000)\n",
    "    # rng = np.random.default_rng()\n",
    "    bestacc = 0\n",
    "    cstar = None\n",
    "    for ic, c in enumerate(cs):\n",
    "\n",
    "        # split into 80/20\n",
    "        fullKd = RBF(xtrain, c)\n",
    "        Ktrain, ytraini, Ktest, ytesti = split2(fullKd, jtrain, jtest, ytrain, ntrain)\n",
    "        # five-fold cross validation\n",
    "        testacc = 0\n",
    "        for k in range(5):\n",
    "            nsplit = int(nfold * k/5)\n",
    "            ktrain1 = np.arange(0, nsplit+1)\n",
    "            ktest = np.arange(nsplit+1, nsplit + nfoldtest-1)\n",
    "            ktrain2 = np.arange(nsplit + nfoldtest-1, nfold)\n",
    "            ktrain = np.hstack([ktrain1, ktrain2]).flatten()\n",
    "            Kfoldtrain, yfoldtraini, Kfoldtest, yfoldtesti = split2(Ktrain, ktrain, ktest, ytraini, nfold)\n",
    "            model = onevsall(yfoldtraini, yfoldtraini, None, yfoldtesti, ks = (Kfoldtrain, Kfoldtest))\n",
    "            for epoch in range(5):\n",
    "                model.train(False, False)    \n",
    "            yhat = model.predict(Kfoldtest, yfoldtesti)\n",
    "            testacc += 0.2 * np.mean(yhat.flatten() == yfoldtesti.flatten())\n",
    "            cvfullnew[ic, i, k] = [np.mean(model.predict(Kfoldtrain, yfoldtraini).flatten() == yfoldtraini.flatten()),\n",
    "                                    np.mean(yhat.flatten() == yfoldtesti.flatten())]\n",
    "        print(f\"{i} run : {c}: {testacc}, {bestacc}, {cstar}\")\n",
    "        np.save(open(\"fullGaussCVFINAL\", \"wb\"), cvfullnew)\n",
    "        \n",
    "        \n",
    "        if testacc > bestacc:\n",
    "            bestacc = testacc\n",
    "            cstar = c\n",
    "#             yhat = model.predict(Ktest)\n",
    "#             testerr[i] = 1 - np.mean(yhat.flatten() == ytesti.flatten())\n",
    "    #train final model for run\n",
    "    fullKd = RBF(xtrain, cstar)\n",
    "    Ktrainfinal, ytraini, Ktestfinal, ytesti = split2(fullKd, jtrain, jtest, ytrain, ntrain)\n",
    "    finalmodel = onevsall(ytrain, ytraini, None, ytesti, ks = (Ktrainfinal, Ktestfinal))\n",
    "    for epoch in range(5):\n",
    "        finalmodel.train(False, False)\n",
    "    finalyhat = finalmodel.predict(Ktestfinal, ytesti)\n",
    "    cstars[i] = cstar\n",
    "    testerr[i] = 1 - (finalmodel.predict(finalmodel.Ktest, finalmodel.ytest).flatten() == finalmodel.ytest.flatten()).mean()\n",
    "    print(f\"{i} runs finished. Dstar: {cstar}, Testerr: {testerr[i]}, Time: {time.time() -start}\")\n",
    "    np.save(open(\"GaussCVNew\", \"wb\"), testerr)\n",
    "    np.save(open(\"cstarsGaussNew\", \"wb\"), cstars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
