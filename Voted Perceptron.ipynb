{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "import torch\n",
    "(xtrain, ytrain), (xtest, ytest) = fashion_mnist.load_data()\n",
    "ytrain, ytest = ytrain.copy(), ytest.copy()\n",
    "ytrain[ytrain != 8] = 0\n",
    "ytrain[ytrain == 8] = 1\n",
    "ytest[ytest != 8] = 0\n",
    "ytest[ytest == 8] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = xtrain.reshape(60000, 784)\n",
    "xtest = xtest.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.032266666666666666\n",
      "10: 0.0245\n",
      "20: 0.024016666666666665\n",
      "30: 0.024016666666666665\n",
      "40: 0.023283333333333333\n",
      "50: 0.023533333333333333\n",
      "60: 0.023683333333333334\n",
      "70: 0.02295\n",
      "80: 0.0228\n",
      "90: 0.023133333333333332\n"
     ]
    }
   ],
   "source": [
    "N, D = xtrain.shape\n",
    "Wtotal = np.zeros(D)\n",
    "b = 0\n",
    "c = 0\n",
    "epoch = 0\n",
    "W = np.zeros(D)\n",
    "btotal = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "    nerr = 0\n",
    "    for i in range(N):\n",
    "        yhat = int(W.dot(xtrain[i]) + b >= 0)\n",
    "        if yhat == ytrain[i]:\n",
    "            c += 1\n",
    "        else:\n",
    "            Wtotal += c*W\n",
    "            btotal += c*b\n",
    "            W = W + (ytrain[i] - yhat) * xtrain[i]\n",
    "            b += (ytrain[i] - yhat)\n",
    "            c = 0\n",
    "            nerr += 1\n",
    "    btotal /= Wtotal.sum()\n",
    "    Wtotal /= Wtotal.sum()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"{epoch}: {nerr/N}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ytrain[i] - yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, nnodes, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.w0 = np.random.normal(0, 0.01, (nnodes[0], 784))\n",
    "        self.w1 = np.random.normal(0, 0.01, (nnodes[1], nnodes[0]))\n",
    "        self.w2 = np.random.normal(0, 0.01, (nnodes[2], nnodes[1]))\n",
    "        self.b0 = np.random.normal(0, 0.01, (nnodes[0], 1))\n",
    "        self.b1 = np.random.normal(0, 0.01, (nnodes[1], 1))        \n",
    "        self.b2 = np.random.normal(0, 0.01, (nnodes[2], 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lenx = 1 if len(x.shape) == 1 else x.shape[0]\n",
    "        self.a0 = (self.w0.dot(x.reshape((x.shape[-1], lenx))) + self.b0).reshape(self.w0.shape[0], 1)\n",
    "        self.h0 = sigmoid(self.a0)\n",
    "        print(self.w1.shape, self.h0.shape, self.b1.shape)\n",
    "        self.a1 = (self.w1.dot(self.h0) + self.b1).reshape(self.w1.shape[0], 1)\n",
    "        self.h1 = sigmoid(self.a1)\n",
    "        self.a2 = self.w2.dot(self.h1) + self.b2\n",
    "        self.h2 = sigmoid(self.a2)\n",
    "        return self.h2\n",
    "    \n",
    "    def gradient(self, x, y):\n",
    "        print(y, 1/self.h2, -1*y/self.h2)\n",
    "        E_h2 = -1*y/self.h2 + (1-y)/(1-self.h2)\n",
    "        h2_w2 = self.h1 * self.h2 * (1 - self.h2)\n",
    "        E_w2 = h2_w2 * E_h2\n",
    "        # 1\n",
    "        h1_w1 = self.h0.dot(self.h1 * (1-self.h1))\n",
    "        h2_h1 = (self.h2 * (1-self.h2)).dot(self.w2.T)\n",
    "        E_h1 = E_h2 * h2_h1\n",
    "        return E_h1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 784)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLP([31, 17, 1], 10)\n",
    "mlp.w0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 31) (31, 1) (17, 1)\n",
      "1 [[2.03288515]] [[-2.03288515]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (31,1) and (17,1) not aligned: 1 (dim 1) != 17 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-302-62c3446c6e06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-300-91a539fa10b0>\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mE_w2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh2_w2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mE_h2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mh1_w1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mh2_h1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mE_h1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mE_h2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mh2_h1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (31,1) and (17,1) not aligned: 1 (dim 1) != 17 (dim 0)"
     ]
    }
   ],
   "source": [
    "mlp.forward(xtrain[0])\n",
    "mlp.gradient(xtrain[0], ytrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [2.01368948] [-2.01368948]\n",
      "[-0.25254974 -0.2491898  -0.25124734 -0.25278761 -0.25355198 -0.25481376\n",
      " -0.24923622 -0.25922887 -0.25019262 -0.25563198 -0.25302872 -0.24597462\n",
      " -0.25172313 -0.24437084 -0.25540867 -0.25896087 -0.24480481] [-0.25254975 -0.2491898  -0.25124733 -0.2527876  -0.25355199 -0.25481375\n",
      " -0.24923622 -0.25922888 -0.25019261 -0.25563199 -0.25302872 -0.24597462\n",
      " -0.25172313 -0.24437084 -0.25540868 -0.25896087 -0.24480482]\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-8\n",
    "l1 = np.zeros(17)\n",
    "l2 = np.zeros(17)\n",
    "for i in range(17):\n",
    "    mlp.w2[0,i] += eps\n",
    "    l1[i] = -np.log(mlp.forward(xtrain[0]))\n",
    "    mlp.w2[0,i] -= (2 * eps)\n",
    "    l2[i] = -np.log(mlp.forward(xtrain[0]))\n",
    "    mlp.w2[0,i] += eps\n",
    "grad = (l1-l2) / (2*eps)\n",
    "print(grad, mlp.gradient(xtrain[0], ytrain[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losstotal(x, y, w0, w1, w2, b0, b1, b2):\n",
    "    output = forward(x, y, w0, w1, w2, b0, b1, b2)[-1]\n",
    "    return loss(output, y).sum()/x.shape[0]\n",
    "def loss(h2, y):\n",
    "    return -((1 - y) * np.log((1 - h2)) + y * np.log(h2))\n",
    "def gradients(x, y, w0, w1, w2, b0, b1, b2):\n",
    "    \"\"\"provides the gradients for a single sample\"\"\"\n",
    "    x = x.reshape(1, 784)\n",
    "    a0, a1, a2, h0, h1, h2 = forward(x, y, w0, w1, w2, b0, b1, b2)\n",
    "    # Variable Notation: E_w1 is E diff wrt w1\n",
    "    # w2\n",
    "    h2_w2 = h1 * h2*(1-h2)\n",
    "    E_h2 = (-y/h2 + (1-y)/(1-h2))\n",
    "    E_w2 = h2_w2 * E_h2\n",
    "    #w1\n",
    "    h1_w1 = h0.T.dot((h1*(1-h1)))\n",
    "    h2_h1 = ((h2*(1-h2))).dot(w2.T)\n",
    "    E_h1 = E_h2 * h2_h1\n",
    "    E_w1 = E_h1 * h1_w1\n",
    "    #w0\n",
    "    h0_w0 = x.T.dot(h0*(1-h0))\n",
    "    h1_h0 = (h1*(1-h1)).dot(w1.T)\n",
    "    h1_h0 = w1 * ((h1*(1-h1)))\n",
    "    E_w0 = h0_w0.dot(h1_h0.dot(E_h2*h2_h1.T))\n",
    "    E_w0 = E_h1.dot(h1_h0.T) * h0_w0\n",
    "    # bias terms\n",
    "    h2_b2 = h2*(1-h2)\n",
    "    E_b2 = h2_b2*E_h2\n",
    "    h1_b1 = h1*(1-h1)\n",
    "    E_b1 = E_h2*h2_h1.T*h1_b1\n",
    "    h0_b0 = h0*(1-h0)\n",
    "    E_b0 = E_h2*h2_h1.T*h1_h0.T*h0_b0\n",
    "    E_b0 = E_h1.dot(h1_h0.T)*h0_b0\n",
    "    return E_w0, E_w1, E_w2.T, E_b0, E_b1, E_b2\n",
    "def forward(x, y, w0, w1, w2, b0, b1, b2):\n",
    "    a0 = x.dot(w0) + b0\n",
    "    h0 = logistic(a0)\n",
    "    a1 = h0.dot(w1) + b1\n",
    "    h1 = logistic(a1)\n",
    "    a2 = h1.dot(w2) + b2\n",
    "    h2 = logistic(a2)\n",
    "    return a0, a1, a2, h0, h1, h2\n",
    "def logistic(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def lprime(x):\n",
    "    return logistic(x) * (1 - logistic(x))\n",
    "def update(xtrain, ytrain, w0, w1, w2, b0, b1, b2, learning_rate = 0.01):\n",
    "    \"\"\"update function which was originally\n",
    "            written for task 3.4 optimization \"\"\"\n",
    "    xtrain = xtrain\n",
    "    n = xtrain.shape[0]\n",
    "    w0gradtotal = np.zeros_like(w0)\n",
    "    w1gradtotal = np.zeros_like(w1)\n",
    "    w2gradtotal = np.zeros_like(w2)\n",
    "    b0gradtotal = np.zeros_like(b0)\n",
    "    b1gradtotal = np.zeros_like(b1)\n",
    "    b2gradtotal = np.zeros_like(b2)\n",
    "    for i in range(n):\n",
    "        w0grad, w1grad, w2grad, b0grad, b1grad, b2grad = gradients(xtrain[i], ytrain[i], w0, w1, w2, b0, b1, b2)\n",
    "        w0gradtotal += w0grad\n",
    "        w1gradtotal += w1grad\n",
    "        w2gradtotal += w2grad\n",
    "        b1gradtotal += b1grad.sum()\n",
    "        b0gradtotal += b0grad\n",
    "        b2gradtotal += b2grad\n",
    "    # update parameters\n",
    "    w0 -= learning_rate * w0gradtotal\n",
    "    w1 -= learning_rate * w1gradtotal\n",
    "    w2 -= learning_rate * w2gradtotal\n",
    "    b0 -= learning_rate * b0gradtotal\n",
    "    b1 -= learning_rate * b1gradtotal\n",
    "    b2 -= learning_rate * b2gradtotal\n",
    "    return w0, w1, w2, b0, b1, b2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c591e3c1ceca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mw0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mb0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mw1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mw2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "w0 = np.random.normal(0, 0.1, (784, 32))\n",
    "b0 = np.random.normal(0, 0.1, (1, 32))\n",
    "w1 = np.random.normal(0, 0.1, (32, 16))\n",
    "b1 = np.random.normal(0, 0.1, (1, 16))\n",
    "w2 = np.random.normal(0, 0.1, (16, 1))\n",
    "b2 = np.random.normal(0, 0.1, (1, 1))\n",
    "epochs = 500\n",
    "accs = np.zeros(epochs)\n",
    "losses = np.zeros(epochs)\n",
    "devacc = np.zeros(epochs)\n",
    "x = xtrain[:100]\n",
    "y = ytrain[:100]\n",
    "js = np.array([i for i in range(100)])\n",
    "for i in range(epochs):\n",
    "    np.random.shuffle(js) #shuffle order to use for training\n",
    "    w0, w1, w2, b0, b1, b2 = update(x[js], y[js], w0, w1, w2, b0, b1, b2, learning_rate = 0.1)\n",
    "    yhat = forward(x, y, w0, w1, w2, b0, b1, b2)[-1].round(0)\n",
    "    accs[i] = 1 - np.mean(np.abs(y.flatten()-yhat.flatten()))\n",
    "    l = (losstotal(x, y, w0, w1, w2, b0, b1, b2))\n",
    "    losses[i] = l\n",
    "#     devhat = forward(devimgs, devlabels, w0, w1, w2, b0, b1, b2)[-1].round(0)\n",
    "#     devacc[i] = 1 - np.mean(np.abs(devlabels - devhat))\n",
    "    if i%1==0:\n",
    "        print(f\"{i}: {accs[i]:.5f}, {l:.6f}, {devacc[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
